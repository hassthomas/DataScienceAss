{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1_newVersion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassthomas/DataScienceAss1/blob/master/A1_myModel.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTs11WubmRhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download data (-q is the quiet mode)\n",
        "! wget -q https://www.dropbox.com/s/lhb1awpi769bfdr/test.csv?dl=1 -O test.csv # download test data from dropbox and store in file\n",
        "! wget -q https://www.dropbox.com/s/gudb5eunj700s7j/train.csv?dl=1 -O train.csv # download train data from dropbox and store in file\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrsga6qkouO1",
        "colab_type": "code",
        "outputId": "d1d9b8e0-09d3-42c2-9122-682437a4196d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        }
      },
      "source": [
        "import pandas as pd                                     # import library for data processing, CSV file input/output and data manipulation\n",
        "\n",
        "Xy_train = pd.read_csv('train.csv', engine='python')    # read training data from file and store in variable\n",
        "\n",
        "X_train = Xy_train.drop(columns=['price_rating'])       # store training data without the output in variable\n",
        "y_train = Xy_train[['price_rating']]                    # store training data output in variable\n",
        "\n",
        "print('traning', len(X_train))                          # print length (how many columns) of training data\n",
        "Xy_train.price_rating.hist()                            # Make a histogram of the tran data frame’s based on the price rating to get a better understanding how the data looks like\n",
        "\n",
        "X_test = pd.read_csv('test.csv', engine='python')       # read training data from file and store in variable\n",
        "testing_ids = X_test.Id                                 # store the IDs of testing data in variable\n",
        "print('testing', len(X_test))                           # print length (how many columns) of testing data\n",
        "\n",
        "Xy_train.head()                                         # show first 5 columns\n",
        "Xy_train.describe()                                     # give further information about the data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "traning 7631\n",
            "testing 7632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>thumbnail_url</th>\n",
              "      <th>medium_url</th>\n",
              "      <th>xl_picture_url</th>\n",
              "      <th>host_id</th>\n",
              "      <th>host_acceptance_rate</th>\n",
              "      <th>host_listings_count</th>\n",
              "      <th>host_total_listings_count</th>\n",
              "      <th>neighbourhood_group_cleansed</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>accommodates</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>beds</th>\n",
              "      <th>square_feet</th>\n",
              "      <th>guests_included</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>maximum_nights</th>\n",
              "      <th>minimum_minimum_nights</th>\n",
              "      <th>maximum_minimum_nights</th>\n",
              "      <th>minimum_maximum_nights</th>\n",
              "      <th>maximum_maximum_nights</th>\n",
              "      <th>minimum_nights_avg_ntm</th>\n",
              "      <th>maximum_nights_avg_ntm</th>\n",
              "      <th>availability_30</th>\n",
              "      <th>availability_60</th>\n",
              "      <th>availability_90</th>\n",
              "      <th>availability_365</th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>number_of_reviews_ltm</th>\n",
              "      <th>review_scores_rating</th>\n",
              "      <th>review_scores_accuracy</th>\n",
              "      <th>review_scores_cleanliness</th>\n",
              "      <th>review_scores_checkin</th>\n",
              "      <th>review_scores_communication</th>\n",
              "      <th>review_scores_location</th>\n",
              "      <th>review_scores_value</th>\n",
              "      <th>license</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>calculated_host_listings_count_entire_homes</th>\n",
              "      <th>calculated_host_listings_count_private_rooms</th>\n",
              "      <th>calculated_host_listings_count_shared_rooms</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>price_rating</th>\n",
              "      <th>Id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.631000e+03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7629.000000</td>\n",
              "      <td>7629.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7622.000000</td>\n",
              "      <td>7627.000000</td>\n",
              "      <td>7626.000000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7629.000000</td>\n",
              "      <td>7627.000000</td>\n",
              "      <td>7628.000000</td>\n",
              "      <td>7630.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7629.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "      <td>7631.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.729931e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.322847</td>\n",
              "      <td>14.322847</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.516315</td>\n",
              "      <td>-73.589346</td>\n",
              "      <td>3.428253</td>\n",
              "      <td>1.112831</td>\n",
              "      <td>1.343516</td>\n",
              "      <td>1.743771</td>\n",
              "      <td>446.436364</td>\n",
              "      <td>1.822566</td>\n",
              "      <td>8.787970</td>\n",
              "      <td>740.683790</td>\n",
              "      <td>7.076923</td>\n",
              "      <td>9.785611</td>\n",
              "      <td>739.700563</td>\n",
              "      <td>742.244267</td>\n",
              "      <td>8.738920</td>\n",
              "      <td>741.579832</td>\n",
              "      <td>8.930677</td>\n",
              "      <td>20.122920</td>\n",
              "      <td>33.010877</td>\n",
              "      <td>113.226183</td>\n",
              "      <td>29.039575</td>\n",
              "      <td>12.065784</td>\n",
              "      <td>93.630358</td>\n",
              "      <td>9.613478</td>\n",
              "      <td>9.319743</td>\n",
              "      <td>9.739712</td>\n",
              "      <td>9.728345</td>\n",
              "      <td>9.664657</td>\n",
              "      <td>9.432822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.908531</td>\n",
              "      <td>5.020705</td>\n",
              "      <td>0.711964</td>\n",
              "      <td>0.051369</td>\n",
              "      <td>1.531162</td>\n",
              "      <td>0.442537</td>\n",
              "      <td>9636.966846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.141532e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>91.178241</td>\n",
              "      <td>91.178241</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.030925</td>\n",
              "      <td>0.042372</td>\n",
              "      <td>2.052919</td>\n",
              "      <td>0.474237</td>\n",
              "      <td>0.934098</td>\n",
              "      <td>1.155192</td>\n",
              "      <td>554.153682</td>\n",
              "      <td>1.411883</td>\n",
              "      <td>136.363186</td>\n",
              "      <td>1302.838095</td>\n",
              "      <td>27.015490</td>\n",
              "      <td>136.732663</td>\n",
              "      <td>1302.376392</td>\n",
              "      <td>1301.670541</td>\n",
              "      <td>99.436534</td>\n",
              "      <td>1301.840294</td>\n",
              "      <td>11.167839</td>\n",
              "      <td>21.979619</td>\n",
              "      <td>34.275417</td>\n",
              "      <td>129.375965</td>\n",
              "      <td>48.159902</td>\n",
              "      <td>18.849201</td>\n",
              "      <td>8.661235</td>\n",
              "      <td>0.820385</td>\n",
              "      <td>1.091052</td>\n",
              "      <td>0.728883</td>\n",
              "      <td>0.739262</td>\n",
              "      <td>0.689070</td>\n",
              "      <td>0.902338</td>\n",
              "      <td>NaN</td>\n",
              "      <td>17.950559</td>\n",
              "      <td>17.850555</td>\n",
              "      <td>2.078313</td>\n",
              "      <td>0.692580</td>\n",
              "      <td>1.871970</td>\n",
              "      <td>0.611870</td>\n",
              "      <td>5576.696895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.277000e+03</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.404540</td>\n",
              "      <td>-73.951930</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.224305e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.498330</td>\n",
              "      <td>-73.602985</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4927.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.290398e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.519820</td>\n",
              "      <td>-73.579930</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>248.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9660.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.266535e+08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.534180</td>\n",
              "      <td>-73.565795</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>800.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1125.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>201.000000</td>\n",
              "      <td>32.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.140000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14424.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.079089e+08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1277.000000</td>\n",
              "      <td>1277.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.700200</td>\n",
              "      <td>-73.480770</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>3283.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>11684.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>999.000000</td>\n",
              "      <td>11684.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>8354.100000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>365.000000</td>\n",
              "      <td>563.000000</td>\n",
              "      <td>161.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>13.540000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>20045.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       thumbnail_url  medium_url  ...  price_rating            Id\n",
              "count            0.0         0.0  ...   7631.000000   7631.000000\n",
              "mean             NaN         NaN  ...      0.442537   9636.966846\n",
              "std              NaN         NaN  ...      0.611870   5576.696895\n",
              "min              NaN         NaN  ...      0.000000      0.000000\n",
              "25%              NaN         NaN  ...      0.000000   4927.500000\n",
              "50%              NaN         NaN  ...      0.000000   9660.000000\n",
              "75%              NaN         NaN  ...      1.000000  14424.500000\n",
              "max              NaN         NaN  ...      2.000000  20045.000000\n",
              "\n",
              "[8 rows x 45 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAASJUlEQVR4nO3df5BdZX3H8fe3hB+V2CQ0NmUgNWHM\njBOgKtkB/DHtLrQQoBo6VScOrcGmk9piR6c/RihjsQojTKW0UrWTMYxBGRYatUlRxqYhO451AhIF\nwo8iS4iWDJNUEqOrSAvz7R/3ib1u98e9u/eeBJ/3a+ZOznme55zzPWdPPvfec+7ejcxEklSHnzvS\nBUiSmmPoS1JFDH1JqoihL0kVMfQlqSJzjnQBU1m4cGEuWbJkxsv/8Ic/5MQTT+xdQT1iXd2xru5Y\nV3d+FuvauXPndzPzFRN2ZuZR+1ixYkXOxvbt22e1fL9YV3esqzvW1Z2fxbqA+3OSXPXyjiRVxNCX\npIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVeSo/hqG2dq19xCXX/nFxre75/pLGt+m\nJHXCV/qSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1J\nqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SK\nGPqSVBFDX5IqYuhLUkUMfUmqSMehHxHHRMQ3I+KuMr80Iu6NiNGIuCMijivtx5f50dK/pG0dV5X2\nxyPiwl7vjCRpat280n8v8Fjb/A3ATZn5KuAgsLa0rwUOlvabyjgiYjmwGjgdWAl8IiKOmV35kqRu\ndBT6EXEqcAnwqTIfwHnApjJkI3BpmV5V5in955fxq4DhzHw+M58CRoGze7ETkqTORGZOPyhiE/AR\n4OXAnwOXAzvKq3kiYjFwd2aeEREPAysz8+nS9yRwDvDBssxnS/uGssymcdtaB6wDWLRo0Yrh4eEZ\n79z+A4fY99yMF5+xM0+ZN2X/2NgYc+fObaiazllXd6yrO9bVndnUNTQ0tDMzBybqmzPdwhHxW8D+\nzNwZEYMzqqALmbkeWA8wMDCQg4Mz3+TNt23mxl3T7mLP7blscMr+kZERZrNf/WJd3bGu7lhXd/pV\nVyeJ+EbgLRFxMXAC8AvA3wPzI2JOZr4AnArsLeP3AouBpyNiDjAPeLat/bD2ZSRJDZj2mn5mXpWZ\np2bmElo3Yu/JzMuA7cBby7A1wOYyvaXMU/rvydY1pC3A6vLpnqXAMuC+nu2JJGlas7n28X5gOCKu\nBb4JbCjtG4DPRMQocIDWEwWZ+UhE3Ak8CrwAXJGZL85i+5KkLnUV+pk5AoyU6d1M8OmbzPwx8LZJ\nlr8OuK7bIiVJveFv5EpSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmq\niKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY\n+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEv\nSRWZNvQj4oSIuC8iHoyIRyLir0v70oi4NyJGI+KOiDiutB9f5kdL/5K2dV1V2h+PiAv7tVOSpIl1\n8kr/eeC8zHwN8FpgZUScC9wA3JSZrwIOAmvL+LXAwdJ+UxlHRCwHVgOnAyuBT0TEMb3cGUnS1KYN\n/WwZK7PHlkcC5wGbSvtG4NIyvarMU/rPj4go7cOZ+XxmPgWMAmf3ZC8kSR2JzJx+UOsV+U7gVcDH\ngb8BdpRX80TEYuDuzDwjIh4GVmbm06XvSeAc4INlmc+W9g1lmU3jtrUOWAewaNGiFcPDwzPeuf0H\nDrHvuRkvPmNnnjJvyv6xsTHmzp3bUDWds67uWFd3rKs7s6lraGhoZ2YOTNQ3p5MVZOaLwGsjYj7w\nBeDVM6qks22tB9YDDAwM5ODg4IzXdfNtm7lxV0e72FN7Lhucsn9kZITZ7Fe/WFd3rKs71tWdftXV\n1ad3MvN7wHbg9cD8iDicqKcCe8v0XmAxQOmfBzzb3j7BMpKkBnTy6Z1XlFf4RMTPA78JPEYr/N9a\nhq0BNpfpLWWe0n9Ptq4hbQFWl0/3LAWWAff1akckSdPr5NrHycDGcl3/54A7M/OuiHgUGI6Ia4Fv\nAhvK+A3AZyJiFDhA6xM7ZOYjEXEn8CjwAnBFuWwkSWrItKGfmQ8Br5ugfTcTfPomM38MvG2SdV0H\nXNd9mZKkXvA3ciWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCX\npIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVJFp/zC6pInt2nuIy6/8\nYuPb3XP9JY1vUz87fKUvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQl\nqSKGviRVxNCXpIoY+pJUkWlDPyIWR8T2iHg0Ih6JiPeW9pMiYmtEPFH+XVDaIyI+FhGjEfFQRJzV\ntq41ZfwTEbGmf7slSZpIJ6/0XwD+LDOXA+cCV0TEcuBKYFtmLgO2lXmAi4Bl5bEO+CS0niSAa4Bz\ngLOBaw4/UUiSmjFt6GfmM5n5jTL9A+Ax4BRgFbCxDNsIXFqmVwG3ZssOYH5EnAxcCGzNzAOZeRDY\nCqzs6d5IkqYUmdn54IglwFeAM4DvZOb80h7AwcycHxF3Addn5ldL3zbg/cAgcEJmXlvaPwA8l5kf\nHbeNdbTeIbBo0aIVw8PDM965/QcOse+5GS8+Y2eeMm/K/rGxMebOndtQNZ2zru54fnXHurozm7qG\nhoZ2ZubARH0d/+WsiJgLfA54X2Z+v5XzLZmZEdH5s8cUMnM9sB5gYGAgBwcHZ7yum2/bzI27mv/j\nYHsuG5yyf2RkhNnsV79YV3c8v7pjXd3pV10dfXonIo6lFfi3ZebnS/O+ctmG8u/+0r4XWNy2+Kml\nbbJ2SVJDOvn0TgAbgMcy82/burYAhz+BswbY3Nb+zvIpnnOBQ5n5DPBl4IKIWFBu4F5Q2iRJDenk\nvekbgd8DdkXEA6XtL4HrgTsjYi3wbeDtpe9LwMXAKPAj4F0AmXkgIj4MfL2M+1BmHujJXkiSOjJt\n6JcbsjFJ9/kTjE/giknWdQtwSzcFSpJ6x9/IlaSKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWp\nIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi\n6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+\nJFXE0Jekihj6klQRQ1+SKjJt6EfELRGxPyIebms7KSK2RsQT5d8FpT0i4mMRMRoRD0XEWW3LrCnj\nn4iINf3ZHUnSVDp5pf9pYOW4tiuBbZm5DNhW5gEuApaVxzrgk9B6kgCuAc4BzgauOfxEIUlqzrSh\nn5lfAQ6Ma14FbCzTG4FL29pvzZYdwPyIOBm4ENiamQcy8yCwlf//RCJJ6rPIzOkHRSwB7srMM8r8\n9zJzfpkO4GBmzo+Iu4DrM/OrpW8b8H5gEDghM68t7R8AnsvMj06wrXW03iWwaNGiFcPDwzPeuf0H\nDrHvuRkvPmNnnjJvyv6xsTHmzp3bUDWds67ueH51x7q6M5u6hoaGdmbmwER9c2ZVFZCZGRHTP3N0\nvr71wHqAgYGBHBwcnPG6br5tMzfumvUudm3PZYNT9o+MjDCb/eoX6+qO51d3rKs7/aprpp/e2Vcu\n21D+3V/a9wKL28adWtoma5ckNWimob8FOPwJnDXA5rb2d5ZP8ZwLHMrMZ4AvAxdExIJyA/eC0iZJ\natC0700j4nZa1+QXRsTTtD6Fcz1wZ0SsBb4NvL0M/xJwMTAK/Ah4F0BmHoiIDwNfL+M+lJnjbw5L\nkvps2tDPzHdM0nX+BGMTuGKS9dwC3NJVdZKknvI3ciWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JF\nDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jaki0/7lLEmq\n1ZIrv3jEtv3plSf2Zb2+0pekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY\n+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKNB76EbEyIh6PiNGIuLLp7UtSzRoN\n/Yg4Bvg4cBGwHHhHRCxvsgZJqlnTr/TPBkYzc3dm/jcwDKxquAZJqlbTfxj9FOA/2+afBs5pHxAR\n64B1ZXYsIh6fxfYWAt+dxfIzEjdMO+SI1NUB6+qO51d3rKsLQzfMqq5XTtbRdOhPKzPXA+t7sa6I\nuD8zB3qxrl6yru5YV3esqzu11dX05Z29wOK2+VNLmySpAU2H/teBZRGxNCKOA1YDWxquQZKq1ejl\nncx8ISLeA3wZOAa4JTMf6eMme3KZqA+sqzvW1R3r6k5VdUVm9mO9kqSjkL+RK0kVMfQlqSIvydCf\n7qscIuL4iLij9N8bEUva+q4q7Y9HxIUN1/WnEfFoRDwUEdsi4pVtfS9GxAPl0dOb2x3UdXlE/Ffb\n9v+grW9NRDxRHmsaruumtpq+FRHfa+vr5/G6JSL2R8TDk/RHRHys1P1QRJzV1tfP4zVdXZeVenZF\nxNci4jVtfXtK+wMRcX/DdQ1GxKG2n9dftfX17WtZOqjrL9pqericUyeVvn4er8URsb1kwSMR8d4J\nxvTvHMvMl9SD1g3gJ4HTgOOAB4Hl48b8MfCPZXo1cEeZXl7GHw8sLes5psG6hoCXlek/OlxXmR87\ngsfrcuAfJlj2JGB3+XdBmV7QVF3jxv8JrRv/fT1eZd2/BpwFPDxJ/8XA3UAA5wL39vt4dVjXGw5v\nj9ZXndzb1rcHWHiEjtcgcNdsz4Fe1zVu7JuBexo6XicDZ5XplwPfmuD/ZN/OsZfiK/1OvsphFbCx\nTG8Czo+IKO3Dmfl8Zj4FjJb1NVJXZm7PzB+V2R20fk+h32bz1RcXAlsz80BmHgS2AiuPUF3vAG7v\n0banlJlfAQ5MMWQVcGu27ADmR8TJ9Pd4TVtXZn6tbBeaO786OV6T6evXsnRZV5Pn1zOZ+Y0y/QPg\nMVrfVtCub+fYSzH0J/oqh/EH7CdjMvMF4BDwix0u28+62q2l9Ux+2AkRcX9E7IiIS3tUUzd1/U55\nG7kpIg7/At1RcbzKZbClwD1tzf06Xp2YrPZ+Hq9ujT+/EvjXiNgZra86adrrI+LBiLg7Ik4vbUfF\n8YqIl9EKzs+1NTdyvKJ16fl1wL3juvp2jh11X8NQg4j4XWAA+PW25ldm5t6IOA24JyJ2ZeaTDZX0\nL8Dtmfl8RPwhrXdJ5zW07U6sBjZl5ottbUfyeB3VImKIVui/qa35TeV4/RKwNSL+o7wSbsI3aP28\nxiLiYuCfgWUNbbsTbwb+PTPb3xX0/XhFxFxaTzTvy8zv93LdU3kpvtLv5KscfjImIuYA84BnO1y2\nn3UREb8BXA28JTOfP9yemXvLv7uBEVrP/o3UlZnPttXyKWBFp8v2s642qxn31ruPx6sTk9V+xL9m\nJCJ+ldbPcFVmPnu4ve147Qe+QO8ua04rM7+fmWNl+kvAsRGxkKPgeBVTnV99OV4RcSytwL8tMz8/\nwZD+nWP9uFHRzwetdye7ab3dP3zz5/RxY67gp2/k3lmmT+enb+Tupnc3cjup63W0blwtG9e+ADi+\nTC8EnqBHN7Q6rOvktunfBnbk/900eqrUt6BMn9RUXWXcq2ndVIsmjlfbNpYw+Y3JS/jpm2z39ft4\ndVjXr9C6T/WGce0nAi9vm/4asLLBun758M+PVnh+pxy7js6BftVV+ufRuu5/YlPHq+z7rcDfTTGm\nb+dYzw5ukw9ad7a/RStAry5tH6L16hngBOCfyn+A+4DT2pa9uiz3OHBRw3X9G7APeKA8tpT2NwC7\nykm/C1jbcF0fAR4p298OvLpt2d8vx3EUeFeTdZX5DwLXj1uu38frduAZ4H9oXTNdC7wbeHfpD1p/\nDOjJsv2Bho7XdHV9CjjYdn7dX9pPK8fqwfJzvrrhut7Tdn7toO1JaaJzoKm6ypjLaX24o325fh+v\nN9G6Z/BQ28/q4qbOMb+GQZIq8lK8pi9JmiFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXkfwE3\nJCTrEGvuJgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vFDJ3lNmE6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model training and tuning\n",
        "import numpy as np  # library for linear algebra\n",
        "from sklearn.compose import ColumnTransformer # to transform columns seperately\n",
        "from sklearn.datasets import fetch_openml # Fetch dataset from openml by name or dataset id.\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer # for completing missing values\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder # standarsize data by removing the mean and scaling to unit variance, encode categorial features\n",
        "from sklearn.linear_model import LogisticRegression # to apply the logistic regression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV  # to split the data into test and train\n",
        "from xgboost.sklearn import XGBClassifier #to apply XGBoost\n",
        "\n",
        "np.random.seed(0) # generate random seed for generating consintent testing\n",
        "\n",
        "# ADD MORE FEATURES TO INCREASE INFORMATION IN MODEL\n",
        "numeric_features = ['host_total_listings_count', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'square_feet', 'guests_included',\n",
        "                    'minimum_nights', 'maximum_nights', 'availability_30', 'availability_60',\t'availability_90',\t'availability_365', \n",
        "                    'number_of_reviews', 'review_scores_rating','review_scores_accuracy', 'review_scores_cleanliness',\n",
        "                    'review_scores_checkin', 'review_scores_communication','review_scores_location', \n",
        "                    'review_scores_value', 'calculated_host_listings_count', 'reviews_per_month'] # select the numeric features\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())])  #Sequentially apply a list of transforms and a final estimator; SimpleImputer: replaces missing value with median for numeric_features\n",
        "                                    #StandardScaler: Normalize the data \n",
        "\n",
        "categorical_features = [ 'host_response_time', 'host_neighbourhood', 'city', 'cancellation_policy', 'property_type', 'is_business_travel_ready', 'room_type', \n",
        "                        'host_is_superhost', 'host_identity_verified', 'neighbourhood_cleansed',\n",
        "                        'instant_bookable',  'require_guest_phone_verification'] # select the categorical features \n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])  #OneHotEncoder: transform into vector\n",
        "\n",
        " #   Applies transformers to columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)]) # transforms data\n",
        "\n",
        "\n",
        "#set training and testing data with the chosen numerical and categorical features; so that the others are not noted anymore\n",
        "X_train = X_train[[*numeric_features, *categorical_features]] \n",
        "X_test = X_test[[*numeric_features, *categorical_features]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U3ZEswV5rj3",
        "colab_type": "code",
        "outputId": "cd2c07d3-e5c8-4622-9c8d-645578c33810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#--------------- XGB CLASSIFIER ---------------\n",
        "#create Pipeline that applies preprocessor which was defined above and then uses xgb as classifier\n",
        " \n",
        "pipeline1 = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('regressor', XGBClassifier(\n",
        "                          objective='multi:softmax', seed=1))])\n",
        "\n",
        "# `__` denotes attribute \n",
        "# (e.g. regressor__n_estimators means the `n_estimators` param for `regressor`\n",
        "#  which is our xgb)\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'regressor__n_estimators': [50, 100], # test first 50 and then 100 estimators\n",
        "    'regressor__max_depth':[10, 20]     # use a maximum test depth of 10 and 20\n",
        "}\n",
        "\n",
        "\n",
        "# GridSearchCV: implements a “fit” and a “score” method. Find the best parameters to use.\n",
        "#   Do Cross-validation 5 times\n",
        "#   n_jobs = 2 means running two jobs in parallel\n",
        "#   verbose - give messages\n",
        "#   evaluate the test set on accuracy\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline1, param_grid, cv=5, verbose=3, n_jobs=2, \n",
        "    scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X_train, y_train) #fitting model with data\n",
        "print('best score {}'.format(grid_search.best_score_))  #printing the accuracy\n",
        "\n",
        "xgb_best = grid_search.best_estimator_ #save the best model\n",
        "print(grid_search.best_params_)  #print best parameters\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  20 out of  20 | elapsed:  2.4min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best score 0.7376499548107847\n",
            "{'preprocessor__num__imputer__strategy': 'mean', 'regressor__max_depth': 10, 'regressor__n_estimators': 50}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsqND8zm6ayD",
        "colab_type": "code",
        "outputId": "0d9c9769-3537-4c91-decc-8153fabc33f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#--------------- RANDOM FOREST ---------------\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier #import needed library\n",
        "\n",
        "#create Pipeline that applies preprocessor which was defined above and then uses RandomForest as classifier\n",
        "pipeline2 = Pipeline(steps=[('preprocessor', preprocessor), ('rf', RandomForestClassifier())])\n",
        "\n",
        "#control flexibility by settings\n",
        "paramForest = {\"rf__n_estimators\": [500],\n",
        "             \"rf__max_depth\": [60],\n",
        "             \"rf__min_samples_split\": [8],\n",
        "             \"rf__min_samples_leaf\": [1]\n",
        "             }\n",
        "\n",
        "rf_gs = GridSearchCV(pipeline2, paramForest, cv=5, verbose=3, n_jobs=2, scoring='accuracy')  \n",
        "\n",
        "\n",
        "rf_gs.fit(X_train, y_train)  #fitting model with data\n",
        "print('best score {}'.format(rf_gs.best_score_)) #print accuracy\n",
        "\n",
        "\n",
        "rf_best = rf_gs.best_estimator_ #save the best model\n",
        "print(rf_gs.best_params_) #print best parameters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  1.3min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/pipeline.py:354: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self._final_estimator.fit(Xt, y, **fit_params)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best score 0.7381742012065906\n",
            "{'rf__max_depth': 60, 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 8, 'rf__n_estimators': 500}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BATFrYDm8SIa",
        "colab_type": "code",
        "outputId": "d3137241-96a1-4a1c-edab-14326442897b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#--------------- MLP | Neural Network ---------------\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier #import needed library\n",
        "\n",
        "#create Pipeline that applies preprocessor which was defined above and then uses MLP as classifier\n",
        "pipeline3 = Pipeline(steps=[('preprocessor', preprocessor), ('nn', MLPClassifier())])\n",
        "\n",
        "#control flexibility by settings\n",
        "paramNeural = {\"nn__activation\": [\"logistic\"],\n",
        "             \"nn__solver\": [\"adam\"],\n",
        "             \"nn__alpha\": [0.04],\n",
        "             \"nn__max_iter\": [300],\n",
        "             \"nn__learning_rate\": ['adaptive']\n",
        "             }\n",
        "\n",
        "nn_gs = GridSearchCV(pipeline3, paramNeural, cv=5, verbose=3, n_jobs=2, scoring='accuracy')\n",
        "\n",
        "nn_gs.fit(X_train, y_train) #fitting model with data\n",
        "print('best score {}'.format(nn_gs.best_score_)) #print accuracy\n",
        "\n",
        "nn_best = nn_gs.best_estimator_ #save the best model\n",
        "print(nn_gs.best_params_) #print best parameters\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   5 out of   5 | elapsed:  2.0min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best score 0.7329331105200323\n",
            "{'nn__activation': 'logistic', 'nn__alpha': 0.04, 'nn__learning_rate': 'adaptive', 'nn__max_iter': 300, 'nn__solver': 'adam'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Nh_mv-9pQX",
        "colab_type": "code",
        "outputId": "546d55a7-a6ba-44c2-faff-d3e173994575",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#--------------- USE ENSAMBLED METHODS TO COMBINE (VOTING CLASSIFIER) ---------------\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier #import needed library\n",
        "\n",
        "estimators = [('xgb',xgb_best), ('nn', nn_best), ('rf', rf_best)] #create dictionary by selecting the 3 used models\n",
        "\n",
        "\n",
        "ensemble = VotingClassifier(estimators, voting='hard') #create voting classifier to combine them and set voting to hard\n",
        "\n",
        "ensemble.fit(X_train, y_train) #fitting model with data\n",
        "print('best score final: ', ensemble.score(X_train, y_train)) #print final accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "best score final:  0.9318568994889267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PF6WrzdKmJ97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prediction & generating the submission file\n",
        "y_pred = ensemble.predict(X_test)\n",
        "pd.DataFrame(\n",
        "    {'Id': testing_ids, 'price_rating':y_pred}).to_csv('final_submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
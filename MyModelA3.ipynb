{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MyModelA3.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"fQhSr_LqSIg4","colab_type":"code","colab":{}},"source":["!wget -q https://l1nna.com/372/Assignment/A2-3/train.csv\n","!wget -q https://l1nna.com/372/Assignment/A2-3/test.csv"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uaABvQpluwjs","colab_type":"code","outputId":"e3a43026-9d9d-4187-adb0-5f809fdf99f3","executionInfo":{"status":"ok","timestamp":1586545998685,"user_tz":-120,"elapsed":2027,"user":{"displayName":"Thomas Hass","photoUrl":"","userId":"07524976909550567906"}},"colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["# import libraries\n","import pandas as pd\n","import csv\n","import re\n","\n","# read train data from file and save in variable\n","xy_train_df = pd.read_csv('train.csv')\n","\n","# read test data from file and save in variable; use id as row label\n","x_test_df  = pd.read_csv('test.csv', index_col='id')\n","\n","# calculate length of review description (how many characters) and sort the table by the length(ascending)\n","xy_train_df['length'] = xy_train_df.apply(lambda x: len(x.review), axis=1)\n","#filtering text\n","xy_train_df['review'] = xy_train_df['review'].apply(lambda x: x.lower())\n","xy_train_df['review'] = xy_train_df['review'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n","\n","xy_train_df = xy_train_df.sort_values('length')\n","xy_train_df"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>rating</th>\n","      <th>review</th>\n","      <th>length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>6037</th>\n","      <td>2596</td>\n","      <td>1</td>\n","      <td>five stars_good</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>5353</th>\n","      <td>4643</td>\n","      <td>1</td>\n","      <td>love it_love it</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>2545</th>\n","      <td>8791</td>\n","      <td>1</td>\n","      <td>five stars_good</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>3902</th>\n","      <td>6098</td>\n","      <td>1</td>\n","      <td>five stars_love</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>2850</th>\n","      <td>4609</td>\n","      <td>1</td>\n","      <td>love these_so cute</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5651</th>\n","      <td>518</td>\n","      <td>1</td>\n","      <td>so far its awesome_ok so ill say up front ive ...</td>\n","      <td>5765</td>\n","    </tr>\n","    <tr>\n","      <th>1615</th>\n","      <td>124</td>\n","      <td>1</td>\n","      <td>it works read tips for potential effectiveness...</td>\n","      <td>6740</td>\n","    </tr>\n","    <tr>\n","      <th>5046</th>\n","      <td>7257</td>\n","      <td>1</td>\n","      <td>an exquisitely effective product with an astou...</td>\n","      <td>8082</td>\n","    </tr>\n","    <tr>\n","      <th>4859</th>\n","      <td>7555</td>\n","      <td>1</td>\n","      <td>gorgeous professional looking manicure at home...</td>\n","      <td>8134</td>\n","    </tr>\n","    <tr>\n","      <th>2758</th>\n","      <td>4823</td>\n","      <td>1</td>\n","      <td>waited to write this review until after readin...</td>\n","      <td>12773</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6223 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["        id  rating                                             review  length\n","6037  2596       1                                    five stars_good      15\n","5353  4643       1                                    love it_love it      15\n","2545  8791       1                                    five stars_good      15\n","3902  6098       1                                    five stars_love      16\n","2850  4609       1                                 love these_so cute      19\n","...    ...     ...                                                ...     ...\n","5651   518       1  so far its awesome_ok so ill say up front ive ...    5765\n","1615   124       1  it works read tips for potential effectiveness...    6740\n","5046  7257       1  an exquisitely effective product with an astou...    8082\n","4859  7555       1  gorgeous professional looking manicure at home...    8134\n","2758  4823       1  waited to write this review until after readin...   12773\n","\n","[6223 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"kHeul60Pzc0D","colab_type":"text"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"dHl0DGCyvA7l","colab_type":"code","outputId":"5569a0fd-5eea-4113-d9ff-0a19d73a3189","executionInfo":{"status":"ok","timestamp":1586546005926,"user_tz":-120,"elapsed":2716,"user":{"displayName":"Thomas Hass","photoUrl":"","userId":"07524976909550567906"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["#import libraries\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from sklearn.model_selection import train_test_split\n","\n","#define vocabulary size and max_len\n","vocab_size = 1000\n","max_len = 256\n","\n","#split training set into training and validation set; 80% training, 20% validation\n","xy_train, xy_validation = train_test_split(xy_train_df, test_size=0.2)\n","\n","# print length to be sure about split\n","print(len(xy_train))\n","print(len(xy_validation))\n","\n","# build vocabulary from training set\n","tokenizer = Tokenizer(num_words=vocab_size)\n","tokenizer.fit_on_texts(xy_train.review)\n","\n","# padding is done inside; convert review text to numpy matrix for max length 256 for training, validation and testing set\n","x_train = tokenizer.texts_to_matrix(xy_train.review, mode='binary')[:, :max_len]\n","y_train = xy_train.rating\n","\n","x_valid = tokenizer.texts_to_matrix(xy_validation.review, mode='binary')[:, :max_len]\n","y_valid = xy_validation.rating\n","\n","x_test = tokenizer.texts_to_matrix(x_test_df.review, mode='binary')[:, :max_len]\n","\n","print(x_train.shape[1])\n","print(x_valid.shape)\n","print(x_test.shape)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["4978\n","1245\n","256\n","(1245, 256)\n","(2667, 256)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_EtEv2RivFKP","colab_type":"code","outputId":"afdef6e2-be7b-47ef-d59e-d5eb77317c06","executionInfo":{"status":"ok","timestamp":1586547065728,"user_tz":-120,"elapsed":7579,"user":{"displayName":"Thomas Hass","photoUrl":"","userId":"07524976909550567906"}},"colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","import collections\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam\n","\n","embedding_dim = 100\n","\n","model = keras.Sequential()\n","model.add(keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_len))\n","model.add(keras.layers.Conv1D(128, 5, activation='relu'))\n","model.add(keras.layers.GlobalMaxPooling1D())\n","model.add(keras.layers.Dense(10, activation='relu'))\n","model.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","# compile the model with \"binary_crossentropy\" as loss function\n","# set the metrics to accuracy\n","# Use the Adam optimizer\n","model.compile(\n","    optimizer=Adam(clipnorm=4.),\n","    loss='binary_crossentropy',\n","    metrics=['accuracy'])\n","\n","\n","history = model.fit(x_train,\n","                    y_train,\n","                    epochs=10,\n","                    batch_size=100,\n","                    validation_data=(x_valid, y_valid),\n","                    verbose=1)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","50/50 [==============================] - 1s 13ms/step - loss: 0.4309 - accuracy: 0.8612 - val_loss: 0.3596 - val_accuracy: 0.8811\n","Epoch 2/10\n","50/50 [==============================] - 1s 11ms/step - loss: 0.3783 - accuracy: 0.8748 - val_loss: 0.3598 - val_accuracy: 0.8811\n","Epoch 3/10\n","50/50 [==============================] - 1s 11ms/step - loss: 0.3770 - accuracy: 0.8748 - val_loss: 0.3585 - val_accuracy: 0.8811\n","Epoch 4/10\n","50/50 [==============================] - 1s 11ms/step - loss: 0.3787 - accuracy: 0.8748 - val_loss: 0.3623 - val_accuracy: 0.8811\n","Epoch 5/10\n","50/50 [==============================] - 1s 11ms/step - loss: 0.3775 - accuracy: 0.8748 - val_loss: 0.3598 - val_accuracy: 0.8811\n","Epoch 6/10\n","50/50 [==============================] - 1s 11ms/step - loss: 0.3772 - accuracy: 0.8748 - val_loss: 0.3586 - val_accuracy: 0.8811\n","Epoch 7/10\n","50/50 [==============================] - 1s 11ms/step - loss: 0.3772 - accuracy: 0.8748 - val_loss: 0.3604 - val_accuracy: 0.8811\n","Epoch 8/10\n","50/50 [==============================] - 1s 11ms/step - loss: 0.3765 - accuracy: 0.8748 - val_loss: 0.3632 - val_accuracy: 0.8811\n","Epoch 9/10\n","50/50 [==============================] - 1s 11ms/step - loss: 0.3780 - accuracy: 0.8748 - val_loss: 0.3602 - val_accuracy: 0.8811\n","Epoch 10/10\n","50/50 [==============================] - 1s 11ms/step - loss: 0.3771 - accuracy: 0.8748 - val_loss: 0.3587 - val_accuracy: 0.8811\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z_naN0rn3OlN","colab_type":"code","outputId":"290ef486-dc48-4b9b-8f48-3140e5f19983","executionInfo":{"status":"ok","timestamp":1586547068982,"user_tz":-120,"elapsed":1423,"user":{"displayName":"Thomas Hass","photoUrl":"","userId":"07524976909550567906"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# evaluate model\n","model.evaluate(x_valid, y_valid)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["39/39 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8811\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.36454322934150696, 0.8811244964599609]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"Byj-weFZvaaS","colab_type":"code","outputId":"c6a55fe2-757d-4efa-f353-1f69d6b8978d","executionInfo":{"status":"ok","timestamp":1586547072904,"user_tz":-120,"elapsed":1407,"user":{"displayName":"Thomas Hass","photoUrl":"","userId":"07524976909550567906"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["y_predict = np.squeeze(model.predict_classes(x_valid))\n","\n","from sklearn.metrics import  f1_score\n","from sklearn.metrics import confusion_matrix\n","\n","print(f1_score(y_valid, y_predict, average='micro'))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-24-c215bc58b971>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n","Instructions for updating:\n","Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","0.8811244979919679\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8FDSaQaxvG0q","colab_type":"code","colab":{}},"source":["# run on testing set:\n","y_predict = np.squeeze(model.predict_classes(x_test))\n","\n","pd.DataFrame(\n","    {'id': x_test_df.index,\n","     'rating':y_predict}).to_csv('sample_submission.csv', index=False)"],"execution_count":0,"outputs":[]}]}